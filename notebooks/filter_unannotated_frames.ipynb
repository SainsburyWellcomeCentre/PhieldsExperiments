{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to remove unannotated frames from a dataset that has been partially annotated. All unannotated frames are moved into a new folder called 'unannotated', and a new json saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0,r'C:\\tr-dev\\JARVIS-msi\\JARVIS-HybridNet\\jarvis\\dataset')\n",
    "# import dataset3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load and save datasets of the class dataset3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(json_path):\n",
    "    with open(json_path) as f:\n",
    "        dataset = json.load(f)\n",
    "    return dataset\n",
    "\n",
    "def save_dataset(dataset, json_path):\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create a subfolder and move selected file to that subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_file_to_subdirectory(file_path, subdirectory):\n",
    "    \n",
    "    directory = os.path.dirname(file_path)\n",
    "    subdirectory_path = os.path.join(directory, subdirectory)\n",
    "    if not os.path.exists(subdirectory_path):\n",
    "        os.makedirs(subdirectory_path)\n",
    "    file_name = os.path.basename(file_path)\n",
    "    new_file_path = os.path.join(subdirectory_path, file_name)\n",
    "    os.rename(file_path, new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out frames without annotations. Automatically move the frames out of the corresponding folder (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frames(dataset, recording_dir, moveFiles=True):\n",
    "    filtered_images = []\n",
    "    filtered_annotations = []\n",
    "    annotated_frame_ids = set()\n",
    "    filter_count = 0\n",
    "    total_count = 0\n",
    "    for ann in dataset['annotations']:\n",
    "        annotated_frame_ids.add(ann['image_id'])\n",
    "        filter_count+=1\n",
    "    for img in dataset['images']:\n",
    "        total_count+=1\n",
    "        if img['id'] in annotated_frame_ids:\n",
    "            filtered_images.append(img)\n",
    "        else:\n",
    "            file_path = os.path.join(recording_dir, img['file_name'])\n",
    "            if not os.path.exists(file_path) and moveFiles:\n",
    "                print('Sending ' + file_path + ' to ' + os.path.join(file_path, 'unannotated'))\n",
    "                move_file_to_subdirectory(file_path, 'unannotated')\n",
    "    for ann in dataset['annotations']:\n",
    "        if ann['image_id'] in annotated_frame_ids:\n",
    "            filtered_annotations.append(ann)\n",
    "\n",
    "    dataset['images'] = filtered_images\n",
    "    dataset['annotations'] = filtered_annotations\n",
    "\n",
    "    return dataset, [total_count, filter_count], [filtered_annotations, filtered_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frames(dataset, recording_dir, moveFiles=True):\n",
    "    filtered_images = []\n",
    "    filtered_annotations = []\n",
    "    annotated_frame_ids = set()\n",
    "    filter_count = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for ann in dataset['annotations']:\n",
    "        annotated_frame_ids.add(ann['image_id'])\n",
    "        filter_count += 1\n",
    "\n",
    "    for img in dataset['images']:\n",
    "        total_count += 1\n",
    "        if img['id'] in annotated_frame_ids:\n",
    "            filtered_images.append(img)\n",
    "        else:\n",
    "            file_path = os.path.join(recording_dir, img['file_name'])\n",
    "            if moveFiles:\n",
    "                if os.path.exists(file_path):\n",
    "                    print(f'Moving {file_path} to {os.path.join(recording_dir, \"unannotated\")}')\n",
    "                    move_file_to_subdirectory(file_path, 'unannotated')\n",
    "\n",
    "    for ann in dataset['annotations']:\n",
    "        if ann['image_id'] in annotated_frame_ids:\n",
    "            filtered_annotations.append(ann)\n",
    "\n",
    "    # dataset['images'] = filtered_images # NO! This makes creating a project fail as it changes the index reference in the annotations. May be possible to remap this\n",
    "    dataset['annotations'] = filtered_annotations\n",
    "\n",
    "    return dataset, [total_count, filter_count], [filtered_annotations, filtered_images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'C:\\tr-dev\\JARVIS-msi\\trainingSet\\TR_manyframes_trainingset_tofilter'\n",
    "annotations_dir = os.path.join(data_dir, 'annotations')\n",
    "\n",
    "train_recording_dir = os.path.join(data_dir, 'train')\n",
    "val_recording_dir = os.path.join(data_dir, 'val')\n",
    "\n",
    "train_json_path = os.path.join(annotations_dir, 'instances_train.json')\n",
    "val_json_path = os.path.join(annotations_dir, 'instances_val.json')\n",
    "\n",
    "filtered_train_json_path = os.path.join(annotations_dir, 'filtered_instances_train.json')\n",
    "filtered_val_json_path = os.path.join(annotations_dir, 'filtered_instances_val.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = load_dataset(train_json_path)\n",
    "val_dataset = load_dataset(val_json_path)\n",
    "\n",
    "# Filter jsons\n",
    "filtered_train_dataset,[train_total_count, train_filter_count],[filtered_annotations, filtered_images] = filter_frames(train_dataset, train_recording_dir, moveFiles=False)\n",
    "filtered_val_dataset,[val_total_count, val_filter_count],[filtered_annotations, filtered_images] = filter_frames(val_dataset, val_recording_dir, moveFiles=False)\n",
    "\n",
    "# Save filtered datasets\n",
    "save_dataset(filtered_train_dataset, filtered_train_json_path)\n",
    "save_dataset(filtered_val_dataset, filtered_val_json_path)\n",
    "\n",
    "print(\"Filtered datasets saved successfully.\")\n",
    "print(f'Total training frames = {train_total_count} of which {train_filter_count} are annotated. The rest have been removed in the filtered json')\n",
    "print(f'Total validation frames = {val_total_count} of which {val_filter_count} are annotated. The rest have been removed in the filtered json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
